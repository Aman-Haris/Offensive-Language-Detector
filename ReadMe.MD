# ğŸ›¡ï¸ Offensive Language Detector (Multilingual)

A Flask-based NLP service for detecting offensive language in **English** and **Kannada** text inputs. Built using **SVM (Support Vector Machine)** and trained on publicly available datasets, this tool classifies text as either **offensive** or **not offensive** via a simple API endpoint.

---

## ğŸ“Œ Problem Statement

Detecting offensive and harmful content online is crucial for promoting safer digital environments. This project was developed as part of the **ML Engineer Assessment** for Youth India E-School and includes:

- Multilingual support (English & Kannada)
- One API endpoint (`/detect-offensive`)
- Trained using labeled datasets from open-source repositories
- High performance with real-world test cases

---

## ğŸ§  Features

- ğŸ§¾ Input: A sentence or word in English/Kannada
- ğŸš¦ Output: Boolean (`true` for offensive, `false` otherwise)
- ğŸ”— One-click REST API integration using Flask
- ğŸ’¬ Clean prediction logic using trained SVM classifier
- ğŸ“ Trained on combined datasets with preprocessing included

---

## ğŸš€ How to Run

1. Clone the repository
```
git clone https://github.com/yourusername/offensive-language-detector.git
cd offensive-language-detector
```

2. Install requirements
```
pip install -r requirements.txt
```

3. Run the API server
```
python api.py
```

4. Make a sample API call
Use Postman or curl:

```
curl -X POST http://127.0.0.1:5000/detect-offensive \
     -H "Content-Type: application/json" \
     -d '{"text": "your input text here"}'
```

---

## ğŸ—‚ï¸ Project Structure

```
Offensive-Language-Detector/
â”‚
â”œâ”€â”€ api.py                 # Flask API for predictions
â”œâ”€â”€ Main Program.py        # CLI version for local testing
â”œâ”€â”€ Model Training.py      # Training script for SVM model
â”œâ”€â”€ svm_model.joblib       # Trained classifier (binary)
â”œâ”€â”€ vectorizer.joblib      # CountVectorizer (for encoding text)
â”œâ”€â”€ /Data/                 # Dataset folder (CSV files)
â”œâ”€â”€ ReadMe.txt             # Original brief
â””â”€â”€ README.md              # You're here
```

---

## ğŸ“ˆ Model Performance

The model was trained on 39,221 samples across both languages. Below are the evaluation metrics:

|              | precision | recall | f1-score | support |
| ------------ | --------- | ------ | -------- | ------- |
|           0  |     0.96  |   0.98 |     0.97 |  31237  |
|           1  |     0.93  |   0.84 |     0.88 |    7984 |
|              |           |        |          |         |
|    accuracy  |           |        |     0.95 |   39221 |
|   macro avg  |     0.95  |   0.91 |     0.93 |   39221 |
| weighted avg |      0.95 |   0.95 |     0.95 |   39221 |	

---

## ğŸŒ Dataset Sources

* English Dataset:
profanity-check by vzhou842

* Kannada Dataset:
Hate-Alert-DravidianLangTech

---

## ğŸ§ª Example Inputs & Output

|       Input        |  Output  |
| ------------------ | -------- |
| "You are a fool"   |   true   |
| "Have a nice day"  |   false  |
| "à²¨à³€à²¨à³ à²®à³‚à²°à³à²–"    |   true    |
| "à²¨à³€à²µà³ à²šà³†à²¨à³à²¨à²¾à²—à²¿à²¦à³à²¦à³€à²°à²¿" |   false   |

---

## ğŸ§° Dependencies

* Python 3.x
* Flask
* scikit-learn
* pandas
* joblib

---

## ğŸ§‘â€ğŸ’» Author

Aman Haris
- Submitted for: Youth India E-School â€“ ML Engineer Assessment

---

## ğŸ“œ License

This project is distributed for academic and demonstration purposes. Please credit the author if reused or extended.
